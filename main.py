"""
–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –ø–æ–º–æ—â—å—é Machine Learning
–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω
"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler

plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
pd.set_option('display.float_format', '{:.2f}'.format)

RANDOM_STATE = 42
TEST_SIZE = 0.2


def load_and_prepare_data(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.read_csv(file_path)

    print(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
    print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

    df = df.drop('car_ID', axis=1)
    return df


def exploratory_data_analysis(df):
    """–†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîπ –†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")

    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    sns.histplot(df['price'], bins=40, kde=True, ax=axes[0], color='skyblue')
    axes[0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏', fontsize=14)
    axes[0].set_xlabel('–¶–µ–Ω–∞ ($)', fontsize=12)
    axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', fontsize=12)
    axes[0].grid(alpha=0.3)

    sns.boxplot(y=df['price'], ax=axes[1], color='lightcoral', showmeans=True)
    axes[1].set_title('Boxplot —Ü–µ–Ω', fontsize=14)
    axes[1].set_ylabel('–¶–µ–Ω–∞ ($)', fontsize=12)
    axes[1].grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    stats = df['price'].describe()
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–µ–Ω:")
    print(f"   –ú–∏–Ω: ${stats['min']:,.0f}")
    print(f"   Q1: ${stats['25%']:,.0f}")
    print(f"   –ú–µ–¥–∏–∞–Ω–∞: ${stats['50%']:,.0f}")
    print(f"   Q3: ${stats['75%']:,.0f}")
    print(f"   –ú–∞–∫—Å: ${stats['max']:,.0f}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ: ${stats['mean']:,.0f}")
    print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ${stats['std']:,.0f}")

    Q1 = stats['25%']
    Q3 = stats['75%']
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df['price'] < lower_bound) | (df['price'] > upper_bound)]
    print(f"\nüìà –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤:")
    print(f"   –ì—Ä–∞–Ω–∏—Ü—ã –≤—ã–±—Ä–æ—Å–æ–≤: ${lower_bound:,.0f} - ${upper_bound:,.0f}")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤: {len(outliers)}")
    print(f"   –î–æ–ª—è –≤—ã–±—Ä–æ—Å–æ–≤: {(len(outliers)/len(df))*100:.1f}%")

    skewness = df['price'].skew()
    print(f"\nüìä –°–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: {skewness:.2f}")

    if skewness > 1:
        print("‚û°Ô∏è –°–∏–ª—å–Ω–æ –ø—Ä–∞–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å")
    elif skewness > 0.5:
        print("‚û°Ô∏è –£–º–µ—Ä–µ–Ω–Ω–∞—è –ø—Ä–∞–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å")
    elif skewness < -1:
        print("‚¨ÖÔ∏è –°–∏–ª—å–Ω–æ –ª–µ–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å")
    elif skewness < -0.5:
        print("‚¨ÖÔ∏è –£–º–µ—Ä–µ–Ω–Ω–∞—è –ª–µ–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å")
    else:
        print("‚ÜîÔ∏è –ë–ª–∏–∑–∫–æ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é")

    return stats


def correlation_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
    print("\nüîπ –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π...")

    numeric_features = [
        'wheelbase', 'carlength', 'carwidth', 'carheight',
        'curbweight', 'enginesize', 'boreratio', 'stroke',
        'compressionratio', 'horsepower', 'peakrpm', 'citympg',
        'highwaympg', 'price'
    ]

    numeric_df = df[numeric_features]
    corr_matrix = numeric_df.corr()

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

    price_corr = corr_matrix['price'].drop('price').sort_values()
    colors = ['red' if x < 0 else 'green' for x in price_corr.values]

    bars = ax1.barh(price_corr.index, price_corr.values, color=colors, alpha=0.7)
    ax1.axvline(x=0, color='black', linestyle='-', alpha=0.8)

    for i, (bar, value) in enumerate(zip(bars, price_corr.values)):
        ax1.text(value + (0.01 if value >= 0 else -0.05), i, f'{value:.2f}',
                 va='center', fontweight='bold', fontsize=10)

    ax1.set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–Ω–æ–π', fontsize=14)
    ax1.set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏', fontsize=12)
    ax1.set_ylabel('–ü—Ä–∏–∑–Ω–∞–∫–∏', fontsize=12)
    ax1.grid(axis='x', alpha=0.3)

    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    sns.heatmap(
        corr_matrix,
        mask=mask,
        annot=True,
        cmap='coolwarm',
        center=0,
        square=True,
        fmt='.2f',
        cbar_kws={'shrink': 0.8},
        ax=ax2
    )
    ax2.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π', fontsize=14)

    plt.tight_layout()
    plt.show()

    print("\nüìä –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å —Ü–µ–Ω–æ–π:")
    print("-" * 40)

    strong_corr = price_corr[(price_corr.abs() > 0.7) & (price_corr.index != 'price')]
    if not strong_corr.empty:
        print("üîπ –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
        for feature, corr in strong_corr.items():
            print(f"   {feature}: {corr:.3f}")

    moderate_corr = price_corr[(price_corr.abs() > 0.5) & (price_corr.abs() <= 0.7)]
    if not moderate_corr.empty:
        print("\nüî∏ –£–º–µ—Ä–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
        for feature, corr in moderate_corr.items():
            print(f"   {feature}: {corr:.3f}")

    print("\nüí° –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:")
    if 'enginesize' in numeric_features and abs(corr_matrix.loc['enginesize', 'price']) > 0.5:
        print("   - –†–∞–∑–º–µ—Ä –¥–≤–∏–≥–∞—Ç–µ–ª—è —Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ü–µ–Ω—É")
    if 'curbweight' in numeric_features and abs(corr_matrix.loc['curbweight', 'price']) > 0.5:
        print("   - –í–µ—Å –∞–≤—Ç–æ–º–æ–±–∏–ª—è –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ü–µ–Ω–æ–π")

    return numeric_df, corr_matrix


def prepare_model_data(numeric_df):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏"""
    print("\nüîπ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏...")

    X = numeric_df.drop('price', axis=1)
    y = numeric_df['price']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
    )

    print(f"–†–∞–∑–º–µ—Ä X_train: {X_train.shape}")
    print(f"–†–∞–∑–º–µ—Ä X_test: {X_test.shape}")

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, X_train.columns


def train_and_evaluate_model(X_train, X_test, y_train, y_test):
    """–û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
    print("\nüîπ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    model = RandomForestRegressor(
        n_estimators=100,
        random_state=RANDOM_STATE,
        n_jobs=-1
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:")
    print(f"MSE: {mse:,.2f}")
    print(f"RMSE: {rmse:,.2f}")
    print(f"MAE: {mae:,.2f}")
    print(f"R¬≤ Score: {r2:.4f}")

    mean_price = y_test.mean()
    print(f"\nüìà –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏:")
    print(f"RMSE / –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {(rmse/mean_price)*100:.1f}%")
    print(f"MAE / –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {(mae/mean_price)*100:.1f}%")

    return model, y_pred, {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}


def plot_predictions(y_true, y_pred, metrics, model_name='Random Forest'):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.scatter(y_true, y_pred, alpha=0.6, s=50, color='steelblue', edgecolor='white', linewidth=0.5)

    max_val = max(y_true.max(), y_pred.max())
    plt.plot([0, max_val], [0, max_val], 'r--', lw=2, label='–ò–¥–µ–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ')

    plt.xlabel('–†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ ($)', fontsize=12)
    plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ ($)', fontsize=12)
    plt.title(f'{model_name}\nR¬≤ = {metrics["r2"]:.3f}', fontsize=14)
    plt.grid(alpha=0.3)
    plt.legend()

    plt.subplot(1, 2, 2)
    errors = y_true - y_pred
    plt.hist(errors, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
    plt.axvline(x=0, color='red', linestyle='--', label='–ù–µ—Ç –æ—à–∏–±–∫–∏')
    plt.xlabel('–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ($)', fontsize=12)
    plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=12)
    plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\nMAE = ${metrics["mae"]:,.0f}', fontsize=14)
    plt.grid(alpha=0.3)
    plt.legend()

    plt.tight_layout()
    plt.show()

    return errors


def analyze_results(y_test, y_pred, errors, feature_names, model):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–¥–µ–ª–∏"""
    print("\nüîπ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

    results_df = pd.DataFrame({
        '–†–µ–∞–ª—å–Ω–∞—è_—Ü–µ–Ω–∞': y_test.values,
        '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞': y_pred,
        '–û—à–∏–±–∫–∞': errors,
        '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–û—à–∏–±–∫–∞': np.abs(errors),
        '–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è_–û—à–∏–±–∫–∞_%': (np.abs(errors) / y_test.values) * 100
    })

    print("\nüéØ –¢–æ–ø-5 —Å–∞–º—ã—Ö —Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    accurate_predictions = results_df.nsmallest(5, '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–û—à–∏–±–∫–∞')
    print(accurate_predictions[['–†–µ–∞–ª—å–Ω–∞—è_—Ü–µ–Ω–∞', '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞', '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–û—à–∏–±–∫–∞', '–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è_–û—à–∏–±–∫–∞_%']].round(2))

    print("\n‚ö†Ô∏è –¢–æ–ø-5 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –æ—à–∏–±–æ–∫:")
    large_errors = results_df.nlargest(5, '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–û—à–∏–±–∫–∞')
    print(large_errors[['–†–µ–∞–ª—å–Ω–∞—è_—Ü–µ–Ω–∞', '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞', '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–û—à–∏–±–∫–∞', '–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è_–û—à–∏–±–∫–∞_%']].round(2))

    print("\nüìä –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    feature_importance = pd.DataFrame({
        '–ü—Ä–∏–∑–Ω–∞–∫': feature_names,
        '–í–∞–∂–Ω–æ—Å—Ç—å': model.feature_importances_
    }).sort_values('–í–∞–∂–Ω–æ—Å—Ç—å', ascending=False)

    print(feature_importance.head(10).to_string(index=False))

    plt.figure(figsize=(12, 8))
    top_features = feature_importance.head(10)

    sns.barplot(
        x='–í–∞–∂–Ω–æ—Å—Ç—å',
        y='–ü—Ä–∏–∑–Ω–∞–∫',
        data=top_features,
        hue='–ü—Ä–∏–∑–Ω–∞–∫',
        palette='rocket',
        legend=False,
        dodge=False
    )

    plt.title('–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16)
    plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞', fontsize=12)

    for i, (importance, feature) in enumerate(zip(top_features['–í–∞–∂–Ω–æ—Å—Ç—å'], top_features['–ü—Ä–∏–∑–Ω–∞–∫'])):
        plt.text(importance + 0.001, i, f'{importance:.3f}',
                 va='center', fontweight='bold', fontsize=10)

    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    plt.show()

    print("\nüí° –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    top_3 = feature_importance.head(3)
    for i, (_, row) in enumerate(top_3.iterrows(), 1):
        print(f"{i}. {row['–ü—Ä–∏–∑–Ω–∞–∫']}: {row['–í–∞–∂–Ω–æ—Å—Ç—å']:.3f}")

    return results_df, feature_importance


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöó –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π")
    print("=" * 50)

    try:
        df = load_and_prepare_data('CarPrice_Assignment.csv')
        exploratory_data_analysis(df)
        numeric_df, corr_matrix = correlation_analysis(df)
        X_train, X_test, y_train, y_test, feature_names = prepare_model_data(numeric_df)
        model, y_pred, metrics = train_and_evaluate_model(X_train, X_test, y_train, y_test)
        errors = plot_predictions(y_test, y_pred, metrics)
        results_df, feature_importance = analyze_results(y_test, y_pred, errors, feature_names, model)

        print("\n" + "=" * 50)
        print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üéØ –ú–æ–¥–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç {metrics['r2']*100:.1f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Ü–µ–Ω")
        print(f"üìè –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: ${metrics['mae']:,.0f}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()